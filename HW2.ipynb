{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce4851b6",
   "metadata": {},
   "source": [
    "Q1\n",
    "\n",
    "Defining the Door Options:\n",
    "\n",
    "\n",
    "all_door_options = (1, 2, 3)  # tuple\n",
    "my_door_choice = 1  # 1, 2, 3\n",
    "i_won = 0\n",
    "reps = 100000\n",
    "all_door_options: This is a tuple containing the three doors (labeled 1, 2, 3).\n",
    "my_door_choice: This initializes the player’s first choice of door to 1.\n",
    "i_won: This variable keeps track of how many times the player wins.\n",
    "reps: The number of repetitions (simulations) is set to 100,000.\n",
    "\n",
    "Simulating the Game Loop:\n",
    "\n",
    "for i in range(reps):\n",
    "    secret_winning_door = np.random.choice(all_door_options)\n",
    "A for loop runs the simulation reps times (100,000 times). Inside the loop:\n",
    "\n",
    "secret_winning_door randomly selects which door will have the prize (car) using np.random.choice().\n",
    "\n",
    "\n",
    "Removing the Secret Winning Door:\n",
    "\n",
    "    \n",
    "    all_door_options_list = list(all_door_options)\n",
    "    all_door_options_list.remove(secret_winning_door)\n",
    "all_door_options_list converts the tuple of door options into a list (to allow modification).\n",
    "The remove() method removes the door with the prize (secret_winning_door) from the list so that Monty can only reveal a door with a goat.\n",
    "\n",
    "\n",
    "Handling the Player’s Original Choice:\n",
    "\n",
    "    try:\n",
    "        all_door_options_list.remove(my_door_choice)\n",
    "    except:\n",
    "        pass\n",
    "This block tries to remove the player's original door choice (my_door_choice) from all_door_options_list.\n",
    "If my_door_choice is the same as secret_winning_door, it will raise an exception because the door is already removed, hence the try-except block is used to avoid errors.\n",
    "\n",
    "\n",
    "Revealing a Goat Door:\n",
    "\n",
    "\n",
    "    goat_door_reveal = np.random.choice(all_door_options_list)\n",
    "    all_door_options_list.remove(goat_door_reveal)\n",
    "Monty reveals one of the remaining doors, which must have a goat. This is done using np.random.choice() from the remaining options in all_door_options_list.\n",
    "The revealed goat door is removed from the list since it can no longer be chosen.\n",
    "\n",
    "\n",
    "Switching Doors:\n",
    "\n",
    "    if secret_winning_door != my_door_choice:\n",
    "        all_door_options_list.append(secret_winning_door)\n",
    "If the player's initial choice (my_door_choice) was not the door with the prize, the secret winning door is added back to the list of available doors.\n",
    "The list now contains either the door with the prize or a door with a goat.\n",
    "\n",
    "    my_door_choice = all_door_options_list[0]\n",
    "The player's new choice (after switching) is assigned to the first door in the list (all_door_options_list[0]), which may be either the prize door or the remaining goat door.\n",
    "\n",
    "\n",
    "Checking if the Player Wins:\n",
    "\n",
    "    if my_door_choice == secret_winning_door:\n",
    "        i_won += 1\n",
    "After switching, if the player’s new choice matches the secret winning door, it means the player has won, and i_won is incremented by 1.\n",
    "\n",
    "\n",
    "Calculating the Winning Probability:\n",
    "\n",
    "i_won / reps\n",
    "Finally, the program computes the proportion of wins by dividing the number of wins (i_won) by the total number of simulations (reps), which gives an estimate of the probability of winning using the switching strategy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6493436",
   "metadata": {},
   "source": [
    "Q2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "all_door_options = (1, 2, 3)  # Tuple representing the 3 doors\n",
    "my_door_choice = 1  # Initially choose door 1\n",
    "i_won = 0  # Counter for winsconcis\n",
    "reps = 100000  # Number of simulations\n",
    "\n",
    "\n",
    "for i in range(reps):\n",
    "    # Randomly choose the winning door\n",
    "    secret_winning_door = np.random.choice(all_door_options)\n",
    "    \n",
    "    # If the player swaps, they win if their initial choice was not the winning door\n",
    "    if my_door_choice != secret_winning_door:\n",
    "        i_won += 1  # Player wins if they switch and their initial choice was wrong\n",
    "\n",
    "win_probability = i_won / reps\n",
    "win_probability\n",
    "\n",
    "\n",
    "Compared to the old code, the new code is much easier to follow because it is less lengthy and concise. The code also follows the core idea on how the player switches his choice from the first door, which makes the code more logical and intuitive. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cec4e1",
   "metadata": {},
   "source": [
    "Q3\n",
    "\n",
    "Preferred Version: Code suggested by Chatbox\n",
    "    \n",
    "import numpy as np  #unpackage \n",
    "\n",
    "# set parameters\n",
    "all_door_options = (1, 2, 3)  # Tuple (immutable) representing the 3 doors\n",
    "my_door_choice = 1  # Initially choose door 1\n",
    "i_won = 0  # Counter for wins\n",
    "reps = 100000  # Number of simulations\n",
    "\n",
    "# Run the simulation\n",
    "for i in range(reps):\n",
    "    # Randomly choose the winning door\n",
    "    secret_winning_door = np.random.choice(all_door_options)  #secret door is chosen randomly from the 3 doors\n",
    "    \n",
    "    # If the player swaps, they win if their initial choice was not the winning door\n",
    "    if my_door_choice != secret_winning_door:\n",
    "        i_won += 1  # Player wins if they switch and their initial choice was wrong\n",
    "\n",
    "# Calculate the probability of winning by switching\n",
    "win_probability = i_won / reps  \n",
    "win_probability\n",
    "\n",
    "\n",
    "The provided code is a simulation of the Monty Hall problem, a probability puzzle involving three doors: one hiding a prize (car) and two hiding goats. After a player picks a door, the host (Monty Hall) reveals a goat behind one of the unchosen doors. The player is then given the option to switch doors. The puzzle's key question is whether switching increases the player's chance of winning.\n",
    "    \n",
    "link: https://chatgpt.com/share/66ea04c1-6220-800e-b1b0-7d7986afd322\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb638c62",
   "metadata": {},
   "source": [
    "Q4\n",
    "\n",
    "Here's a quick summary of how the code works:\n",
    "\n",
    "- The code processes a list of words (`words`) to build a Markov chain model.\n",
    "- **`word_used`**: A dictionary that counts how many times each word appears.\n",
    "- **`next_word`**: A dictionary that tracks what words tend to follow each word and how often they do.\n",
    "- The loop goes through each word (except the last one) and:\n",
    "  - Updates the count of the current word in `word_used`.\n",
    "  - Updates the count of the next word in `next_word` for each word pair.\n",
    "  \n",
    "This allows for generating new text by predicting the next word based on the current one.\n",
    "\n",
    "\n",
    "Link: https://chatgpt.com/share/66ea0f67-5228-800e-95fe-c43e531d63c8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdcf285",
   "metadata": {},
   "source": [
    "Q5.1\n",
    "\n",
    "Extension 1\n",
    "Why Use Bigrams?\n",
    "Using bigrams makes the generated text more coherent because it accounts for word pairs, which can capture more meaningful word associations than just using single words. For example, it can help produce more contextually accurate text like \"New York City\" as a unit, rather than \"New\" being followed by any arbitrary word.\n",
    "\n",
    "Character-Specific Markov Chains:\n",
    "If we were to create character-specific Markov chains, we would shift from using words as the basis for transitions to using characters. Let’s sketch how that would work:\n",
    "\n",
    "Instead of splitting the text into words, you would split it into individual characters.\n",
    "You’d then apply the same logic as above, but tracking sequences of characters instead of words.\n",
    "For example, you could build bigrams of characters, where the current bigram of characters predicts the next character.\n",
    "Here’s a simple version of how you might code a character-based Markov chain:\n",
    "\n",
    "\n",
    "char_used = defaultdict(int)\n",
    "next_char = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for i in range(len(text) - 2):\n",
    "    char_bigram = text[i] + text[i+1]\n",
    "    char_used[char_bigram] += 1\n",
    "    next_char[char_bigram][text[i+2]] += 1\n",
    "Here, char_bigram represents two consecutive characters.\n",
    "char_used counts how often each character bigram appears.\n",
    "next_char tracks which character follows each bigram and how often.\n",
    "Example:\n",
    "If text = \"hello\", the bigrams and their next characters would be:\n",
    "\n",
    "First iteration (i=0):\n",
    "\n",
    "Bigram: \"he\"\n",
    "Next character: \"l\"\n",
    "char_used[\"he\"] += 1\n",
    "next_char[\"he\"][\"l\"] += 1\n",
    "Second iteration (i=1):\n",
    "\n",
    "Bigram: \"el\"\n",
    "Next character: \"l\"\n",
    "char_used[\"el\"] += 1\n",
    "next_char[\"el\"][\"l\"] += 1\n",
    "Third iteration (i=2):\n",
    "\n",
    "Bigram: \"ll\"\n",
    "Next character: \"o\"\n",
    "char_used[\"ll\"] += 1\n",
    "next_char[\"ll\"][\"o\"] += 1\n",
    "Summary:\n",
    "Bigrams in words: The code forms bigrams of two consecutive words and tracks which words follow these bigrams, making the text generation more context-aware.\n",
    "Character-specific Markov chains: Instead of working with words, you can adapt the same logic to characters, building sequences based on character bigrams (or even longer sequences). This is useful for generating text character by character, such as in text generation for coding or creative writing.\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "Extension 2 \n",
    "\n",
    "Summary of What the Code Does:\n",
    "Character-specific Bigrams:\n",
    "This extension creates separate Markov chains for each character in the dataset (avatar).\n",
    "It tracks how often each character uses specific bigrams (pairs of words) and what words tend to follow those bigrams.\n",
    "Key Differences from Earlier Extensions:\n",
    "This extension builds character-specific models by associating each character with their unique set of bigrams and next-word transitions.\n",
    "It uses a nested dictionary structure (nested_dict) to store bigrams and next words for each character separately, making it more complex than the basic bigram approach.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00222e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q 5.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670cda4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1\n",
    "\n",
    "Defining the Door Options:\n",
    "\n",
    "\n",
    "all_door_options = (1, 2, 3)  # tuple\n",
    "my_door_choice = 1  # 1, 2, 3\n",
    "i_won = 0\n",
    "reps = 100000\n",
    "all_door_options: This is a tuple containing the three doors (labeled 1, 2, 3).\n",
    "my_door_choice: This initializes the player’s first choice of door to 1.\n",
    "i_won: This variable keeps track of how many times the player wins.\n",
    "reps: The number of repetitions (simulations) is set to 100,000.\n",
    "\n",
    "Simulating the Game Loop:\n",
    "\n",
    "for i in range(reps):\n",
    "    secret_winning_door = np.random.choice(all_door_options)\n",
    "A for loop runs the simulation reps times (100,000 times). Inside the loop:\n",
    "\n",
    "secret_winning_door randomly selects which door will have the prize (car) using np.random.choice().\n",
    "\n",
    "\n",
    "Removing the Secret Winning Door:\n",
    "\n",
    "    \n",
    "    all_door_options_list = list(all_door_options)\n",
    "    all_door_options_list.remove(secret_winning_door)\n",
    "all_door_options_list converts the tuple of door options into a list (to allow modification).\n",
    "The remove() method removes the door with the prize (secret_winning_door) from the list so that Monty can only reveal a door with a goat.\n",
    "\n",
    "\n",
    "Handling the Player’s Original Choice:\n",
    "\n",
    "    try:\n",
    "        all_door_options_list.remove(my_door_choice)\n",
    "    except:\n",
    "        pass\n",
    "This block tries to remove the player's original door choice (my_door_choice) from all_door_options_list.\n",
    "If my_door_choice is the same as secret_winning_door, it will raise an exception because the door is already removed, hence the try-except block is used to avoid errors.\n",
    "\n",
    "\n",
    "Revealing a Goat Door:\n",
    "\n",
    "\n",
    "    goat_door_reveal = np.random.choice(all_door_options_list)\n",
    "    all_door_options_list.remove(goat_door_reveal)\n",
    "Monty reveals one of the remaining doors, which must have a goat. This is done using np.random.choice() from the remaining options in all_door_options_list.\n",
    "The revealed goat door is removed from the list since it can no longer be chosen.\n",
    "\n",
    "\n",
    "Switching Doors:\n",
    "\n",
    "    if secret_winning_door != my_door_choice:\n",
    "        all_door_options_list.append(secret_winning_door)\n",
    "If the player's initial choice (my_door_choice) was not the door with the prize, the secret winning door is added back to the list of available doors.\n",
    "The list now contains either the door with the prize or a door with a goat.\n",
    "\n",
    "    my_door_choice = all_door_options_list[0]\n",
    "The player's new choice (after switching) is assigned to the first door in the list (all_door_options_list[0]), which may be either the prize door or the remaining goat door.\n",
    "\n",
    "\n",
    "Checking if the Player Wins:\n",
    "\n",
    "    if my_door_choice == secret_winning_door:\n",
    "        i_won += 1\n",
    "After switching, if the player’s new choice matches the secret winning door, it means the player has won, and i_won is incremented by 1.\n",
    "\n",
    "\n",
    "Calculating the Winning Probability:\n",
    "\n",
    "i_won / reps\n",
    "Finally, the program computes the proportion of wins by dividing the number of wins (i_won) by the total number of simulations (reps), which gives an estimate of the probability of winning using the switching strategy.\n",
    "\n",
    "\n",
    "\n",
    "Q2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "all_door_options = (1, 2, 3)  # Tuple representing the 3 doors\n",
    "my_door_choice = 1  # Initially choose door 1\n",
    "i_won = 0  # Counter for winsconcis\n",
    "reps = 100000  # Number of simulations\n",
    "\n",
    "\n",
    "for i in range(reps):\n",
    "    # Randomly choose the winning door\n",
    "    secret_winning_door = np.random.choice(all_door_options)\n",
    "    \n",
    "    # If the player swaps, they win if their initial choice was not the winning door\n",
    "    if my_door_choice != secret_winning_door:\n",
    "        i_won += 1  # Player wins if they switch and their initial choice was wrong\n",
    "\n",
    "win_probability = i_won / reps\n",
    "win_probability\n",
    "\n",
    "\n",
    "Compared to the old code, the new code is much easier to follow because it is less lengthy and concise. The code also follows the core idea on how the player switches his choice from the first door, which makes the code more logical and intuitive. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Q3\n",
    "\n",
    "Preferred Version: Code suggested by Chatbox\n",
    "    \n",
    "import numpy as np  #unpackage \n",
    "\n",
    "# set parameters\n",
    "all_door_options = (1, 2, 3)  # Tuple (immutable) representing the 3 doors\n",
    "my_door_choice = 1  # Initially choose door 1\n",
    "i_won = 0  # Counter for wins\n",
    "reps = 100000  # Number of simulations\n",
    "\n",
    "# Run the simulation\n",
    "for i in range(reps):\n",
    "    # Randomly choose the winning door\n",
    "    secret_winning_door = np.random.choice(all_door_options)  #secret door is chosen randomly from the 3 doors\n",
    "    \n",
    "    # If the player swaps, they win if their initial choice was not the winning door\n",
    "    if my_door_choice != secret_winning_door:\n",
    "        i_won += 1  # Player wins if they switch and their initial choice was wrong\n",
    "\n",
    "# Calculate the probability of winning by switching\n",
    "win_probability = i_won / reps  \n",
    "win_probability\n",
    "\n",
    "\n",
    "The provided code is a simulation of the Monty Hall problem, a probability puzzle involving three doors: one hiding a prize (car) and two hiding goats. After a player picks a door, the host (Monty Hall) reveals a goat behind one of the unchosen doors. The player is then given the option to switch doors. The puzzle's key question is whether switching increases the player's chance of winning.\n",
    "    \n",
    "link: https://chatgpt.com/share/66ea04c1-6220-800e-b1b0-7d7986afd322\n",
    "        \n",
    "\n",
    "Q4\n",
    "\n",
    "Here's a quick summary of how the code works:\n",
    "\n",
    "- The code processes a list of words (`words`) to build a Markov chain model.\n",
    "- **`word_used`**: A dictionary that counts how many times each word appears.\n",
    "- **`next_word`**: A dictionary that tracks what words tend to follow each word and how often they do.\n",
    "- The loop goes through each word (except the last one) and:\n",
    "  - Updates the count of the current word in `word_used`.\n",
    "  - Updates the count of the next word in `next_word` for each word pair.\n",
    "  \n",
    "This allows for generating new text by predicting the next word based on the current one.\n",
    "\n",
    "\n",
    "Link: https://chatgpt.com/share/66ea0f67-5228-800e-95fe-c43e531d63c8\n",
    "\n",
    "Q5.1\n",
    "\n",
    "Extension 1\n",
    "Why Use Bigrams?\n",
    "Using bigrams makes the generated text more coherent because it accounts for word pairs, which can capture more meaningful word associations than just using single words. For example, it can help produce more contextually accurate text like \"New York City\" as a unit, rather than \"New\" being followed by any arbitrary word.\n",
    "\n",
    "Character-Specific Markov Chains:\n",
    "If we were to create character-specific Markov chains, we would shift from using words as the basis for transitions to using characters. Let’s sketch how that would work:\n",
    "\n",
    "Instead of splitting the text into words, you would split it into individual characters.\n",
    "You’d then apply the same logic as above, but tracking sequences of characters instead of words.\n",
    "For example, you could build bigrams of characters, where the current bigram of characters predicts the next character.\n",
    "Here’s a simple version of how you might code a character-based Markov chain:\n",
    "\n",
    "\n",
    "char_used = defaultdict(int)\n",
    "next_char = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for i in range(len(text) - 2):\n",
    "    char_bigram = text[i] + text[i+1]\n",
    "    char_used[char_bigram] += 1\n",
    "    next_char[char_bigram][text[i+2]] += 1\n",
    "Here, char_bigram represents two consecutive characters.\n",
    "char_used counts how often each character bigram appears.\n",
    "next_char tracks which character follows each bigram and how often.\n",
    "Example:\n",
    "If text = \"hello\", the bigrams and their next characters would be:\n",
    "\n",
    "First iteration (i=0):\n",
    "\n",
    "Bigram: \"he\"\n",
    "Next character: \"l\"\n",
    "char_used[\"he\"] += 1\n",
    "next_char[\"he\"][\"l\"] += 1\n",
    "Second iteration (i=1):\n",
    "\n",
    "Bigram: \"el\"\n",
    "Next character: \"l\"\n",
    "char_used[\"el\"] += 1\n",
    "next_char[\"el\"][\"l\"] += 1\n",
    "Third iteration (i=2):\n",
    "\n",
    "Bigram: \"ll\"\n",
    "Next character: \"o\"\n",
    "char_used[\"ll\"] += 1\n",
    "next_char[\"ll\"][\"o\"] += 1\n",
    "Summary:\n",
    "Bigrams in words: The code forms bigrams of two consecutive words and tracks which words follow these bigrams, making the text generation more context-aware.\n",
    "Character-specific Markov chains: Instead of working with words, you can adapt the same logic to characters, building sequences based on character bigrams (or even longer sequences). This is useful for generating text character by character, such as in text generation for coding or creative writing.\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "Extension 2 \n",
    "\n",
    "Summary of What the Code Does:\n",
    "Character-specific Bigrams:\n",
    "This extension creates separate Markov chains for each character in the dataset (avatar).\n",
    "It tracks how often each character uses specific bigrams (pairs of words) and what words tend to follow those bigrams.\n",
    "Key Differences from Earlier Extensions:\n",
    "This extension builds character-specific models by associating each character with their unique set of bigrams and next-word transitions.\n",
    "It uses a nested dictionary structure (nested_dict) to store bigrams and next words for each character separately, making it more complex than the basic bigram approach.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Q 5.2\n",
    "I searched up what the \"code word_used\" and \"enumerate()\" is used for in extension1, and \"next_word()\" in extension2\n",
    "\n",
    "\n",
    "Q 5.3\n",
    "\n",
    "Summary:\n",
    "Here’s a full summary of everything we’ve discussed so far:\n",
    "\n",
    "### 1. **Original Markovian Chatbot Code:**\n",
    "   - The original code uses a Markov chain to predict the next word based on the current word.\n",
    "   - Two main dictionaries:\n",
    "     - **`word_used`**: Tracks how often each word appears.\n",
    "     - **`next_word`**: Tracks which word comes after each word and how often.\n",
    "   - For each word in the list `words`, it updates these dictionaries to build word-pair associations.\n",
    "\n",
    "### 2. **Extension 1: Bigram Markov Chains**:\n",
    "   - This extension improves the chatbot by using **bigrams** (pairs of consecutive words) instead of single words to predict the next word.\n",
    "   - **`word_used2`**: Tracks how often each bigram is used.\n",
    "   - **`next_word2`**: Tracks which word follows each bigram and how often.\n",
    "   - This gives the chatbot more context when predicting the next word.\n",
    "\n",
    "### 3. **Extension 2: Character-Specific Markov Chains**:\n",
    "   - The code adds the ability to generate **character-specific Markov chains**, where word patterns are tied to specific speakers in a dataset (like `\"ZUKO\"` or `\"AANG\"`).\n",
    "   - It uses the `character` column from a dataset (`avatar`) to identify which character is speaking and builds separate Markov chains for each character.\n",
    "   - **Key Data Structures**:\n",
    "     - **`word_used2C`**: Tracks how often each character uses a specific bigram.\n",
    "     - **`next_word2C`**: Tracks which word follows a specific bigram for each character.\n",
    "   - This allows the chatbot to simulate the speech patterns of different characters individually.\n",
    "\n",
    "### 4. **Character-Specific Markov Chain Clarification**:\n",
    "   - The code ensures that each character has their own unique Markov chain, allowing the chatbot to generate dialogue in the style of that specific character.\n",
    "\n",
    "### 5. **Simplified Explanation**:\n",
    "   - The character-specific extension makes the chatbot smarter by creating **separate word chains** for each character. It learns how each character speaks by tracking the pairs of words they use and what words usually come next.\n",
    "\n",
    "### Final Overview:\n",
    "- The original code tracks individual words and their successors.\n",
    "- Extension 1 enhances this by using **bigrams** (pairs of words).\n",
    "- Extension 2 creates **character-specific chains**, allowing the chatbot to generate speech for each character based on their unique dialogue style.\n",
    "\n",
    "\n",
    "Link:https://chatgpt.com/share/66ea0f67-5228-800e-95fe-c43e531d63c8\n",
    "        \n",
    "\n",
    "Q6.1\n",
    "The Chatbot was able to concisely provide explanations for each step, and additionally providing examples that could be found in other situations.\n",
    "However, some examples were out of range of the necessary knowledge for this class, and it was confusing.\n",
    "\n",
    "Q6.2\n",
    "Some frusterating things were how it kept listing new examples for each concept that it has introduced already in the past, and it made me realize that CHatbot is not entirely great for regular logic-based conversations. \n",
    "And again, some examples were unnessarily difficult and was not easy to understand. \n",
    "\n",
    "Q6.3\n",
    "Chatbot is a very useful tool when it comes to providing answers for very specific questions, meaning we need to input a prompt that is very precise. It tends to extend on ideas very broadly so it is unfit for asking very open-ended questions.\n",
    "\n",
    "Q7 \n",
    "I have taken AP Statistics in highschool, where the course mainly revolves around remembering formulas, reading many articles and writing answers down by hand.\n",
    "This experience of utiliing Chatbot to store data and understand code is very new to me, which was something I haven't expected in this course. I will try my best to \n",
    "learn the codes and gain insight from Chatbot and other resources to stay on task this semester.\n",
    "\n",
    "Q8.1\n",
    "Summarization of the relevance of key skills in the data science industry:\n",
    "\n",
    "Learning and Adaptability: Essential for keeping up with rapidly evolving technology and tools.\n",
    "Communication: Crucial for explaining complex data insights to non-technical stakeholders.\n",
    "Coding: Fundamental for data manipulation, model building, and automating tasks.\n",
    "Statistics and Data Analysis: Core for interpreting data and making data-driven decisions.\n",
    "Mastering these skills enhances career opportunities and effectiveness in data science roles.\n",
    "\n",
    "Q8.2\n",
    "Summary: \n",
    "    \n",
    "    While some roles may focus more on statistical theory or consulting rather than hands-on coding and data analysis, a strong foundation in these areas is typically expected and highly beneficial.\n",
    "   \n",
    "    For a Career in AI:\n",
    "\n",
    "    Data Science: Important for handling and analyzing data, which is crucial for training AI models.\n",
    "    Other Skills: Include machine learning, programming, mathematics and statistics, algorithms and data structures, domain knowledge, and soft skills.\n",
    "    Roles in Data Science and Statistics:\n",
    "\n",
    "    Data Scientists and Statisticians: Typically require coding and data analysis skills to manipulate data and apply statistical methods, though the emphasis might vary based on specific roles.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Q8.3\n",
    "Relevance of Skills in Data Science and AI\n",
    "Learning and Adaptability: Crucial for staying updated with evolving technologies and tools.\n",
    "Communication: Essential for conveying complex insights to non-technical stakeholders.\n",
    "Coding: Fundamental for data manipulation, model building, and automation in data science and AI.\n",
    "Statistics and Data Analysis: Core for interpreting data and making data-driven decisions.\n",
    "AI Career Path\n",
    "Data Science Foundation: Important for understanding and manipulating data for AI models.\n",
    "Key Skills Needed:\n",
    "Machine Learning: Knowledge of algorithms and model evaluation.\n",
    "Programming: Proficiency in languages like Python or R.\n",
    "Mathematics and Statistics: Understanding of linear algebra, calculus, and probability.\n",
    "Algorithms and Data Structures: For optimizing AI solutions.\n",
    "Domain Knowledge: Relevant to specific applications of AI (e.g., healthcare, finance).\n",
    "Soft Skills: Communication, problem-solving, and teamwork.\n",
    "Data Science and Statistics Roles\n",
    "Coding and Data Analysis: Generally essential for both statisticians and data scientists, although the focus may vary.\n",
    "In summary, a career in AI often requires a solid foundation in data science and a diverse set of skills that enhance both technical and communication capabilities.\n",
    "\n",
    "Link: https://chatgpt.com/share/66ec9879-ed74-800e-a62a-f47b1c16945c\n",
    "        \n",
    "\n",
    "Q8.4\n",
    "\n",
    "A job in AI requires a solid foundation in data science as well as a diverse set of abilities. It includes \n",
    "adaptation to new technologies, excellent communication for communicating complicated ideas, \n",
    "and coding for data manipulation. Machine learning, programming (particularly Python or R), mathematics and statistics, \n",
    "algorithms, and domain knowledge are all important areas of being competent. Problem solving and teamwork \n",
    "are also required for success in this area. After this homework, I am more intrigued in pursuing a career in this area of study\n",
    "since I now have more base knowledge and an idea of what to expect for in the future. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Q8.5\n",
    "\n",
    "Chatbot is very useful in terms of asking precise, and topic-specific questions. It may be that we don't get the answer we want \n",
    "if we ask an open-ended question because it could give you unrelated examples or high level knowldge that we are not looking to delve deep \n",
    "into. It also sometimes provide us incorrect codes, so it is not the best tool to use in that sense. For questions regarding coding, it could \n",
    "only analyze code and explain it's use. If I felt like Chatbot was being confusing, I would rephrase the question more concisely to\n",
    "get the specific answer I am looking for. \n",
    "\n",
    "Q9 Yes\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
